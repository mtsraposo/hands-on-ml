{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:57:16.345262Z",
     "start_time": "2023-06-15T00:57:12.017728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/14 21:57:14 WARN Utils: Your hostname, mr.local resolves to a loopback address: 127.0.0.1; using 192.168.15.9 instead (on interface en0)\n",
      "23/06/14 21:57:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/14 21:57:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "APACHE_SPAM_ASSASSIN = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "DATA_FOLDER = '../data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:57:16.350304Z",
     "start_time": "2023-06-15T00:57:16.348233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def pull_data():\n",
    "    response = requests.get(APACHE_SPAM_ASSASSIN)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    file_paths = [link.get('href') for link in soup.find_all('a')]\n",
    "    file_paths = [path for path in file_paths if path.split('.')[-1] == 'bz2']\n",
    "\n",
    "    available_data = set(os.listdir(DATA_FOLDER))\n",
    "    file_paths = [path for path in file_paths if path not in available_data and path != 'corpus.parquet']\n",
    "\n",
    "    if len(file_paths) == 0:\n",
    "        print('No data to pull')\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(f'Pulling {file_path}')\n",
    "        response = requests.get(f\"{APACHE_SPAM_ASSASSIN}/{file_path}\")\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_object = io.BytesIO(response.content)\n",
    "        tar = tarfile.open(fileobj=file_object, mode=\"r:bz2\")\n",
    "\n",
    "        extract_dir = Path(DATA_FOLDER)\n",
    "        extract_path = extract_dir.joinpath(Path(file_path))\n",
    "\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "        tar.extractall(extract_path)\n",
    "\n",
    "        tar.close()\n",
    "\n",
    "    size = get_directory_size(\"../data\")\n",
    "    print(f\"Data directory size: {size} bytes\")\n",
    "\n",
    "\n",
    "def get_directory_size(directory):\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "\n",
    "    return total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:57:46.318807Z",
     "start_time": "2023-06-15T00:57:46.316098Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to pull\n",
      "Data directory size: 121604826 bytes\n"
     ]
    }
   ],
   "source": [
    "pull_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:57:47.341226Z",
     "start_time": "2023-06-15T00:57:46.943876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def parse_data():\n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "    corpus_df = pd.DataFrame(columns=['date', 'difficulty', 'class', 'collection', 'body'])\n",
    "    for dirpath, dirnames, filenames in os.walk(DATA_FOLDER):\n",
    "        print(dirpath)\n",
    "        for filename in filenames:\n",
    "            corpus_path = os.path.join(dirpath, filename)\n",
    "            corpus_df, successful_files, failed_files = incorporate(df, corpus_path, dirpath, successful_files,\n",
    "                                                                    failed_files)\n",
    "    return corpus_df, successful_files, failed_files\n",
    "\n",
    "\n",
    "def incorporate(df, corpus_path, dirpath, successful_files, failed_files):\n",
    "    rawdata = open(corpus_path, 'rb').read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding = result['encoding']\n",
    "\n",
    "    with open(corpus_path, 'r', encoding=encoding) as f:\n",
    "        [(date, *ids)] = re.findall(r'([\\d]{8})_([a-z]*)_?([a-z]*)_?([\\d]*)\\.tar\\.bz2.*',\n",
    "                                    dirpath)\n",
    "        [difficulty, cls, collection] = parse_ids(ids)\n",
    "        try:\n",
    "            body = f.read()\n",
    "            row = pd.DataFrame({'date': date,\n",
    "                                'difficulty': difficulty,\n",
    "                                'class': cls,\n",
    "                                'collection': collection,\n",
    "                                'body': body}, index=[0, 1, 2, 3, 4])\n",
    "            df = pd.concat([df, row], ignore_index=True)\n",
    "            successful_files.append(corpus_path)\n",
    "        except Exception as E:\n",
    "            print(E)\n",
    "            failed_files.append(corpus_path)\n",
    "    return df, successful_files, failed_files\n",
    "\n",
    "\n",
    "def parse_ids(ids):\n",
    "    cls, difficulty, collection = None, None, None\n",
    "    match ids:\n",
    "        case [cls, '', '']:\n",
    "            difficulty = None\n",
    "            collection = None\n",
    "        case [difficulty, cls, '']:\n",
    "            collection = None\n",
    "        case [difficulty, cls, collection]:\n",
    "            pass\n",
    "        case _:\n",
    "            pass\n",
    "\n",
    "    return [difficulty, cls, collection]\n",
    "\n",
    "\n",
    "def save_as_parquet(df):\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.parquet(f'{DATA_FOLDER}/corpus.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:57:56.000023Z",
     "start_time": "2023-06-15T00:57:55.994879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if 'corpus.parquet' in set(os.listdir(DATA_FOLDER)):\n",
    "    df = spark.read.parquet(f'{DATA_FOLDER}/corpus.parquet')\n",
    "    corpus_df = df.toPandas()\n",
    "else:\n",
    "    corpus_df, successful_files, failed_files = parse_data()\n",
    "    save_as_parquet(corpus_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:58:04.319096Z",
     "start_time": "2023-06-15T00:57:59.070720Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "           date difficulty class collection  \\\n0      20030228       hard   ham       None   \n1      20030228       hard   ham       None   \n2      20030228       hard   ham       None   \n3      20030228       hard   ham       None   \n4      20030228       hard   ham       None   \n...         ...        ...   ...        ...   \n53650  20030228       easy   ham       None   \n53651  20030228       easy   ham       None   \n53652  20030228       easy   ham       None   \n53653  20030228       easy   ham       None   \n53654  20030228       easy   ham       None   \n\n                                                    body  \n0      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n1      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n2      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n3      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n4      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n...                                                  ...  \n53650  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53651  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53652  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53653  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53654  From fork-admin@xent.com  Wed Sep 25 10:24:54 ...  \n\n[53655 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>difficulty</th>\n      <th>class</th>\n      <th>collection</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53650</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53651</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53652</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53653</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53654</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From fork-admin@xent.com  Wed Sep 25 10:24:54 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>53655 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:58:29.789891Z",
     "start_time": "2023-06-15T00:58:29.785283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
